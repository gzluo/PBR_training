{
 "metadata": {
  "name": "",
  "signature": "sha256:cfe66c98bff3401f7abc94f0eb91788df606ac8460fdb1784116fb9e62059aa2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variant-calling training tutorial\n",
      "===\n",
      "Chen Tong\n",
      "===\n",
      "\n",
      "Welcome to my tutorial, enjoy it. \n",
      "\n",
      "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/2.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 2.0 Generic License</a>.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Next-Generation Sequencing basic knowledges"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Please refer to `NGS-basic_training.ipynb` for basic sequencing concepts and software installation and uasage."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exome-Seq"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Please see http://gatkforums.broadinstitute.org/discussion/1204/what-input-files-does-the-gatk-accept-require.\n",
      "* Assume we have two compressed fastq file `NA19129.fq.gz` and `NA19240.fq.gz`.\n",
      "* Download genome data and SNP data from [GATK bundle](ftp://ftp.broadinstitute.org/bundle) \n",
      "    * Login to GATK bundle to check the latest version number by `ncftp -u gsapubftp-anonymous -p '<blank>' ftp.broadinstitute.org/bundle`.\n",
      "    * Download all data using `wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/`. Pay attention to version number `2.8` and genome assemble version `hg19`.\n",
      "    * Download only needed data as listed below:\n",
      "```\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_omni2.5.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_omni2.5.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_phase1.indels.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_phase1.indels.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_phase1.snps.high_confidence.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/1000G_phase1.snps.high_confidence.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/CEUTrio.HiSeq.WGS.b37.bestPractices.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/dbsnp_138.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/dbsnp_138.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/hapmap_3.3.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/hapmap_3.3.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/Mills_and_1000G_gold_standard.indels.hg19.vcf.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/Mills_and_1000G_gold_standard.indels.hg19.vcf.idx.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/snp138CodingDbSnp.txt.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/ucsc.hg19.dict.gz\n",
      "wget -nd --user=gsapubftp-anonymous -r ftp://ftp.broadinstitute.org/bundle/2.8/hg19/ucsc.hg19.fasta.gz\n",
      "```\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reads mapping"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here using [BWA](http://bio-bwa.sourceforge.net/) to map reads to genome."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Constructing genome index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Make sure the chromosoe order in `hg19.fasta` is the same as [GATK recommended](http://gatkforums.broadinstitute.org/discussion/1204/what-input-files-does-the-gatk-accept-require). Usually you can just download `hg19.fasta` from GATK bundle as mentioned before.\n",
      "* Two types of index are needed, one is `bwa` index, the other is `faidx`.\n",
      "* `-a` indicates the method used to construct BWA index. For large genome `bwtsw` should be given."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "bwa index -a bwtsw hg19.fasta -p hg19.fasta\n",
      "samtools faidx hg19.fasta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Single-END reads mapping"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The usage of `bwa` is like `bwa aln bwa_index fastq`.\n",
      "* `-t` tells the number of threads to use.\n",
      "* `-r` [RG-line] will be put in the generated SAM file specifying the ID, the library name and the sample name of the sequences and the sequencing platform. This is needed for GATK. Normally you only need to give the filename (without suffix) to `ID`, `LB` and `SM`. For me, `PL` is always `ILLUMINA`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "bwa aln -t 10 hg19.fasta NA19129.fq.gz >NA19129.sai 2>>NA19129.log\n",
      "bwa samse -r \"@RG\\tID:NA19129\\tLB:NA19129\\tSM:NA19129\\tPL:ILLUMINA\" \\\n",
      "    hg19.fasta NA19129.sai NA19129.fq.gz | gzip > NA19129/NA19129.sam.gz 2>>NA19129.log\n",
      "/bin/rm -f NA19129.sai\n",
      "bwa aln -t 10 hg19.fasta NA19240.fq.gz >NA19240.sai 2>>NA19240.log\n",
      "bwa samse -r \"@RG\\tID:NA19240\\tLB:NA19240\\tSM:NA19240\\tPL:ILLUMINA\" \\\n",
      "    hg19.fasta NA19240.sai NA19240.fq.gz | gzip > NA19240/NA19240.sam.gz 2>>NA19240.log\n",
      "/bin/rm -f NA19240.sai"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Paired-END sequencing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "bwa aln -t 10 hg19.fasta NA19129_1.fq.gz >NA19129_1.sai 2>>NA19129.log\n",
      "bwa aln -t 10 hg19.fasta NA19129_2.fq.gz >NA19129_2.sai 2>>NA19129.log\n",
      "bwa sampe -r \"@RG\\tID:NA19129\\tLB:NA19129\\tSM:NA19129\\tPL:ILLUMINA\" \\\n",
      "    hg19.fasta NA19129_1.sai NA19129_2.sai NA19129_1.fq.gz NA19129_2.fq.gz \\\n",
      "    | gzip > NA19129/NA19129.sam.gz 2>>NA19129.log\n",
      "/bin/rm -f NA19129_1.sai NA19129_2.sai &\n",
      "bwa aln -t 10 hg19.fasta NA19240_1.fq.gz >NA19240_1.sai 2>>NA19240.log\n",
      "bwa aln -t 10 hg19.fasta NA19240_2.fq.gz >NA19240_2.sai 2>>NA19240.log\n",
      "bwa sampe -r \"@RG\\tID:NA19240\\tLB:NA19240\\tSM:NA19240\\tPL:ILLUMINA\" \\\n",
      "    hg19.fasta NA19240_1.sai NA19240_2.sai NA19240_1.fq.gz NA19240_2.fq.gz \\\n",
      "    | gzip > NA19240/NA19240.sam.gz 2>>NA19240.log\n",
      "/bin/rm -f NA19240_1.sai NA19240_2.sai &"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Count the number of mapped reads"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "echo \"#NA19129 total reads: `samtools view -cS NA19129/NA19129.sam.gz`\"\n",
      "echo \"#NA19129 total mapped reads: `samtools view -cS -F4 NA19129/NA19129.sam.gz`\"\n",
      "echo \"#NA19240 total reads: `samtools view -cS NA19240/NA19240.sam.gz`\"\n",
      "echo \"#NA19240 total mapped reads: `samtools view -cS -F4 NA19240/NA19240.sam.gz`\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Mark duplicate reads"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Duplicates originate mostly from DNA prep methods and cause biases that skew variant calling results.\n",
      "* Here we use [`picard`](http://picard.sourceforge.net/index.shtml) to transfer mapping result , mark `duplicates` and output sorted `BAM` file with index created.\n",
      "* `-Xmx8g`: set the maximum allowed memory for this program.\n",
      "* `-jar`: list the commaned to use.\n",
      "* `SO=coordinate`: sort BAM file by reads coordinate.\n",
      "* `VALIDATION_STRINGENCY=LENIENT`: ignore some validation error in BAM files.\n",
      "* `CREATE_INDEX=true`: construct index for BAM files.\n",
      "* dedup\u8fd9\u4e00\u6b65\u53ea\u8981\u5728library\u5c42\u9762\u4e0a\u8fdb\u884c\u5c31\u53ef\u4ee5\u4e86\uff0c\u4f8b\u5982\u4e00\u4e2asample\u5982\u679c\u5efa\u4e86\u591a\u4e2a\u5e93\u7684\u8bdd\uff0c\u5bf9\u6bcf\u4e2a\u5e93\u8fdb\u884cdedup\u5373\u53ef\uff0c\u4e0d\u9700\u8981\u628a\u6240\u6709\u5e93\u5408\u6210\u4e00 \u4e2asample\u518d\u8fdb\u884cdedup\u64cd\u4f5c\u3002\u5176\u5b9e\u5e76\u4e0d\u80fd\u51c6\u786e\u7684\u5b9a\u4e49\u88abmask\u7684reads\u5230\u5e95\u662f\u4e0d\u662fduplicates\uff0c\u91cd\u590d\u5e8f\u5217\u7684\u7a0b\u5ea6\u4e0e\u6d4b\u5e8f\u6df1\u5ea6\u548c\u6587\u5e93\u7c7b\u578b \u90fd\u6709\u5173\u7cfb\u3002\u6700\u4e3b\u8981\u76ee\u7684\u5c31\u662f\u5c3d\u91cf\u51cf\u5c0f\u6587\u5e93\u6784\u5efa\u65f6\u5f15\u5165\u6587\u5e93\u7684PCR bias\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/picard/SortSam.jar SO=coordinate \\\n",
      "    INPUT=NA19129/NA19129.sam.gz OUTPUT=NA19129/NA19129.bam \\\n",
      "    VALIDATION_STRINGENCY=LENIENT >>NA19129.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/picard/MarkDuplicates.jar \\\n",
      "    INPUT=NA19129/NA19129.bam OUTPUT=NA19129/NA19129.dedup.bam \\\n",
      "    METRICS_FILE=NA19129/NA19129.dedup.log CREATE_INDEX=true \\\n",
      "    VALIDATION_STRINGENCY=LENIENT >>NA19129.log 2>&1\n",
      "\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/picard/SortSam.jar SO=coordinate \\\n",
      "    INPUT=NA19240/NA19240.sam.gz OUTPUT=NA19240/NA19240.bam \\\n",
      "    VALIDATION_STRINGENCY=LENIENT >>NA19240.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/picard/MarkDuplicates.jar \\\n",
      "    INPUT=NA19240/NA19240.bam OUTPUT=NA19240/NA19240.dedup.bam \\\n",
      "    METRICS_FILE=NA19240/NA19240.dedup.log CREATE_INDEX=true \\\n",
      "    VALIDATION_STRINGENCY=LENIENT >>NA19240.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Re-align indels and re-calibrate base quality score"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* InDels in reads (expecially near the ends) can trick the mappers to mis-aligning with mismatches.\n",
      "* These artifical mismatches can harm base quality recalibration and variant detection.These\n",
      "* Realignment around indels improve the accuracy of several of the downstream processing steps.\n",
      "* Three types of realignment targets:\n",
      "    * Known sites (e.g. dbSNP, 1000 Genomes)\n",
      "    * Indels seen in original alignments (in CIGARS)\n",
      "    * Sites where evidence suggests a hidden indel\n",
      "* How to generate known sites if not exist?\n",
      "    * \u9996\u5148\uff0c\u5148\u4f7f\u7528\u6ca1\u6709\u7ecf\u8fc7\u77eb\u6b63\u7684\u6570\u636e\u8fdb\u884c\u4e00\u8f6eSNP calling\uff1b\u7136\u540e\uff0c\u6311\u9009\u6700\u53ef\u4fe1\u7684SNP\u4f4d\u70b9\u8fdb\u884cBQSR\u5206\u6790\uff1b\u6700\u540e\uff0c\u5728\u4f7f\u7528\u8fd9\u4e9b\u7ecf\u8fc7BQSR\u7684\u6570\u636e\u8fdb\u884c\u4e00\u6b21\u771f\u6b63\u7684SNP calling\u3002\u8fd9\u51e0\u6b65\u53ef\u80fd\u8981\u91cd\u590d\u597d\u591a\u6b21\u624d\u80fd\u5f97\u5230\u53ef\u9760\u7684\u7ed3\u679c\u3002\n",
      "    * http://gatkforums.broadinstitute.org/discussion/1243/what-are-the-standard-resources-for-non-human-genomes\n",
      "    * http://gatkforums.broadinstitute.org/discussion/1243/what-are-the-standard-resources-for-non-human-genomes\n",
      "    http://gatkforums.broadinstitute.org/discussion/1783/variantrecalibrator-creating-a-truth-data-set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "# Identify what regions to be aligned\n",
      "# Input BAM file not necassary if processing only at known indels.\n",
      "# Using a list of known indels will speed up processing and improve accuracy, \n",
      "# but is not necessary.\n",
      "# Also if you want only focus on known sites for realignment, the bam file \n",
      "# is not needed too.\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T RealignerTargetCreator \\\n",
      "    -nt 10 -R hg19.fasta -known Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -known 1000G_phase1.indels.hg19.vcf -I NA19129/NA19129.dedup.bam \\\n",
      "    -o NA19129/NA19129.dedup.bam.interval.list >>NA19129.log 2>&1\n",
      "#Perform actual alignment\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T IndelRealigner \\\n",
      "    -R hg19.fasta -known Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -known 1000G_phase1.indels.hg19.vcf \\\n",
      "    -targetIntervals NA19129/NA19129.dedup.bam.interval.list \\\n",
      "    -I NA19129/NA19129.dedup.bam -o NA19129/NA19129.dedup.realigned.bam >>NA19129.log 2>&1\n",
      "    \n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T RealignerTargetCreator \\\n",
      "    -nt 10 -R hg19.fasta -known Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -known 1000G_phase1.indels.hg19.vcf -I NA19240/NA19240.dedup.bam \\\n",
      "    -o NA19240/NA19240.dedup.bam.interval.list >>NA19240.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T IndelRealigner \\\n",
      "    -R hg19.fasta -known Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -known 1000G_phase1.indels.hg19.vcf \\\n",
      "    -targetIntervals NA19240/NA19240.dedup.bam.interval.list \\\n",
      "    -I NA19240/NA19240.dedup.bam -o NA19240/NA19240.dedup.realigned.bam >>NA19240.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Quality scores are critical for all downstream analysis.\n",
      "* Systematic biases are a major contributor to bad calls.\n",
      "* Unfortunatelly, the quality scores issued by sequencers are inaccurate and biased.\n",
      "* Base Quality Score Recalibration provides a calibrated error model from which to make mutation calls.\n",
      "    * Per base indel error rate also varies by lane, sequence context and sequencing technology.\n",
      "    * Empirical estimates of base insertion and base deletion error rates unify SNP and indel error models.\n",
      "* Old quality score would be saved in `OQ` tag."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#Model the error modes and recalibrate qualities\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T BaseRecalibrator \\\n",
      "    -R hg19.fasta -knownSites dbsnp_138.hg19.vcf \\\n",
      "    -knownSites Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -knownSites 1000G_phase1.indels.hg19.vcf  \\\n",
      "    -I NA19129/NA19129.dedup.realigned.bam \\\n",
      "    -o NA19129/NA19129.dedup.realigned.before_recal.table >>NA19129.log 2>&1\n",
      "#Write recalibrated data to file\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T PrintReads \\\n",
      "    -R hg19.fasta -I NA19129/NA19129.dedup.realigned.bam \\\n",
      "    -BQSR NA19129/NA19129.dedup.realigned.before_recal.table \\\n",
      "    -o NA19129/NA19129.dedup.realigned.recal.bam >>NA19129.log 2>&1\n",
      "\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T BaseRecalibrator \\\n",
      "    -R hg19.fasta -knownSites dbsnp_138.hg19.vcf \\\n",
      "    -knownSites Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -knownSites 1000G_phase1.indels.hg19.vcf  \\\n",
      "    -I NA19240/NA19240.dedup.realigned.bam \\\n",
      "    -o NA19240/NA19240.dedup.realigned.before_recal.table >>NA19240.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T PrintReads \\\n",
      "    -R hg19.fasta -I NA19240/NA19240.dedup.realigned.bam \\\n",
      "    -BQSR NA19240/NA19240.dedup.realigned.before_recal.table \\\n",
      "    -o NA19240/NA19240.dedup.realigned.recal.bam >>NA19240.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#Generate quality score for re-calibrated BAM\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T BaseRecalibrator \\\n",
      "    -R hg19.fasta -knownSites dbsnp_138.hg19.vcf \\\n",
      "    -knownSites Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -knownSites 1000G_phase1.indels.hg19.vcf -I NA19129/NA19129.dedup.realigned.bam \\\n",
      "    -BQSR NA19129/NA19129.dedup.realigned.before_recal.table \\\n",
      "    -o NA19129/NA19129.dedup.realigned.after_recal.table >>NA19129.log 2>&1\n",
      "#Quality score plot before and after recalibration\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T AnalyzeCovariates \\\n",
      "    -R hg19.fasta -before NA19129/NA19129.dedup.realigned.before_recal.table \\\n",
      "    -after NA19129/NA19129.dedup.realigned.after_recal.table \\\n",
      "    -plots NA19129/NA19129.dedup.realigned.recal_plot.pdf \\\n",
      "    -csv NA19129/NA19129.dedup.realigned.recal_plot.csv >>NA19129.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data compression with reduced reads"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Reducing the size of BAM files allowing greater running performence.\n",
      "* Read\u2010based compression keeps only essential information for variant calling.\n",
      "* How to judge if compression work properly\n",
      "    * Reads should be stripped out of all extra tags in the BAM file.\n",
      "    * A quick variant calling run on a small region of the genome on both full and reduced BAM and look for highly similar variant calls.\n",
      "       * If number s are too disparate (either compressed BAM is missing variants or is carrying many new variants), a more in-depth look at the file is advised.\n",
      "       * Coverage test with `DiagnoseTargets` should yield similar results for variant regions and capped results for concensus regions.\n",
      "* It is not necessary to do this step when calling variants using `HaplotypeCaller` or there is very few samples. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T ReduceReads \\\n",
      "    -R hg19.fasta -I NA19129/NA19129.dedup.realigned.recal.bam \\\n",
      "    -O NA19129/NA19129.dedup.realigned.recal.reduced.bam "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SNP calling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Genetic variant or random machine noise = large scale Bayesian inference problem\n",
      "* `UnifiedGenotyper`(shorted as `UG`)\n",
      "    * Call SNPs and indels separately by considering each variant locus independently\n",
      "    * Accepts any ploidy\n",
      "    * Polled calling\n",
      "    * High sample numbers\n",
      "* `HaplotypeCaller`(shorted as `HC`)\n",
      "    * Call SNPs, indels, and some SVs simultaneously by performing a local de-novo assembly\n",
      "    * More accurate, especially for indels\n",
      "    * Will eventually replace `UG`\n",
      "* Tips for accelrating the running process\n",
      "    * Reduce BAM\n",
      "    * The command line argument which most determines the runtime of the `HaplotypeCaller` is `-minPruning`. This argument controls the amount of pruning that is performed on the local de-novo assembly graph which is generated for every variant region. The default value is `-minPruning 1` which means events have to been seen by more than 1 read in order to remain in the graph. This is a very conservative default designed not to miss anything. By raising this threshold fewer haplotypes will need to be evaluated and this reduces the runtime. The optimal value for this parameter depends on your project design and so experimentation is required."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "# For Exome-Seq\n",
      "# -L: contains a list of the targeted intervals we wanted to sequence. \n",
      "# Normally we can get this interval file from the Producter of the capture-chip \n",
      "# we used. \n",
      "# Otherwise we can get this from UCSC--Table brower by adding 10 or 20 bp to annotated\n",
      "# exon regions.\n",
      "# Usually I will supply a BED format file to HC. It also accepts files in other format.\n",
      "# Plase check the link in http://gatkforums.broadinstitute.org/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals#latest to see in detail.\n",
      "\n",
      "# variant calling for each sample individually\n",
      "\n",
      "# \u2013genotyping_mode: This specifies how we want the program to determine the alternate \n",
      "#    alleles to use for genotyping. \n",
      "#    In the default DISCOVERY mode, the program will choose the most likely alleles \n",
      "#    out of those it sees in the data. \n",
      "#    In GENOTYPE_GIVEN_ALLELES mode, the program will only use the alleles passed in \n",
      "#    from a VCF file (using the -alleles argument). \n",
      "#    This is useful if you just want to determine if a sample has a specific genotype of \n",
      "#    interest and you are not interested in other alleles.\n",
      "\n",
      "# \u2013stand_emit_conf: Emission confidence threshold. \n",
      "#    This is the minimum confidence threshold (phred-scaled) at which the program should \n",
      "#    emit sites that appear to be possibly variant.\n",
      "\n",
      "# \u2013stand_call_conf: Calling confidence threshold\n",
      "#    This is the minimum confidence threshold (phred-scaled) at which the program should \n",
      "#    emit variant sites as called. If a site's associated genotype has a confidence \n",
      "#    score lower than the calling threshold, the program will emit the site as filtered \n",
      "#    and will annotate it as LowQual. This threshold separates high confidence calls \n",
      "#    from low confidence calls.\n",
      "\n",
      "# The terms called and filtered are tricky because they can mean different things \n",
      "# depending on context. In ordinary language, people often say a site was called \n",
      "# if it was emitted as variant. But in the GATK's technical language, \n",
      "# saying a site was called means that that site passed the confidence threshold test. \n",
      "# For filtered, it's even more confusing, because in ordinary language, \n",
      "# when people say that sites were filtered, they usually mean that \n",
      "# those sites successfully passed a filtering test. \n",
      "# However, in the GATK's technical language, the same phrase (saying that sites were filtered)\n",
      "# means that those sites failed the filtering test. \n",
      "# In effect, it means that those would be filtered out if the filter was used to \n",
      "# actually remove low-confidence calls from the callset, instead of just tagging them. \n",
      "# In both cases, both usages are valid depending on the point of view of the person \n",
      "# who is reporting the results. So it's always important to check what is the context \n",
      "# when interpreting results that include these terms.\n",
      "\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller \n",
      "    -R hg19.fasta -L hg19.refseqGene.exonPlus20.bed \\\n",
      "    -I NA19129/NA19129.dedup.realigned.recal.bam \\\n",
      "    -o NA19129/NA19129.dedup.realigned.recal.vcf \\\n",
      "    -stand_call_conf 30.0 -stand_emit_conf 10.0 -minPruning 3 --emitRefConfidence GVCF \\\n",
      "    --variant_index_type LINEAR --variant_index_parameter 128000 >>NA19129.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "# For Whole-Genome-Seq\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller \n",
      "    -R hg19.fasta \\\n",
      "    -I NA19129/NA19129.dedup.realigned.recal.bam \\\n",
      "    -o NA19129/NA19129.dedup.realigned.recal.vcf \\\n",
      "    -stand_call_conf 30.0 -stand_emit_conf 10.0 -minPruning 3 --emitRefConfidence GVCF \\\n",
      "    --variant_index_type LINEAR --variant_index_parameter 128000 >>NA19129.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#Merge all gvcfs generated for each sample into one gvcf\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T CombineGVCFs \\\n",
      "    -R hg19.fasta -o Exosome.mergeGVCF.vcf \\\n",
      "    --variant NA19129/NA19129.dedup.realigned.recal.vcf  \\\n",
      "    --variant NA19240/NA19240.dedup.realigned.recal.vcf >>merge_snp_call.log 2>&1\n",
      "\n",
      "#Joint genotyping\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK3/GenomeAnalysisTK.jar -T GenotypeGVCFs \\\n",
      "    -R hg19.fasta -o Exosome.genotypeGVCF.vcf \\\n",
      "    --variant Exosome.mergeGVCF.vcf >>merge_snp_call.log 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Raw callsets are often very large and full of false positive mutation calls. So further work is needed before this callset can be used for any meaningful analysis."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "VCF and GVCF format description"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GVCF stands for Genomic VCF. A GVCF is a kind of VCF, so the basic format specification is the same as for a regular VCF (see the spec documentation [here](http://vcftools.sourceforge.net/specs.html), but a Genomic VCF contains extra information.\n",
      "\n",
      "What we're covering here is strictly limited to GVCFs produced by `HaplotypeCaller` in GATK versions `3.0 and above`. The term GVCF is sometimes used simply to describe VCFs that *contain a record for every position in the genome (or interval of interest) regardless of whether a variant was detected at that site or not* (such as VCFs produced by `UnifiedGenotyper` with `--output_mode EMIT_ALL_SITES`).\n",
      "\n",
      "The records in a gVCF include an accurate estimation of how confident we are in the determination that the sites are `homozygous-reference or not`. This estimation is generated by the HaplotypeCaller's built-in [reference model](http://www.broadinstitute.org/gatk/guide/article?id=4042). \n",
      "\n",
      "With GVCF, you get a gVCF with individual variant records for variant sites, but the non-variant sites are grouped together into non-variant block records that represent intervals of sites for which the `genotype quality (GQ)` is within a certain range or band. The GQ ranges are defined in the `##GVCFBlock` line of the gVCF header. The purpose of the blocks (also called banding) is to keep file size down, and there is no downside for the downstream analysis, so we do recommend using the `-GVCF` option.\n",
      "\n",
      "The first thing you'll notice, hopefully, is the <NON_REF> symbolic allele listed in every record's `ALT` field. This provides us with a way to represent the possibility of having a `non-reference allele` at this site, and to indicate our confidence either way.\n",
      "\n",
      "Note that toward the end of this snippet, you see multiple consecutive non-variant block records. These were not merged into a single record because the sites they contain belong to different ranges of GQ (which are defined in the header).\n",
      "\n",
      "`##INFO=<ID=ID,Number=number,Type=type,Description=\u201ddescription\u201d>`\n",
      "\n",
      "Possible Types for INFO fields are: Integer, Float, Flag, Character, and String.\n",
      "\n",
      "The Number entry is an `Integer that describes the number of values that can be included with the INFO field`. For example, if the INFO field contains a single number, then this value should be 1; if the INFO field describes a pair of numbers, then this value should be 2 and so on. If the field has one value per alternate allele then this value should be 'A'; if the field has one value for each possible genotype (more relevant to the FORMAT tags) then this value should be 'G'.  If the number of possible values varies, is unknown, or is unbounded, then this value should be '.'. The 'Flag' type indicates that the INFO field does not contain a Value entry, and hence the Number should be 0 in this case. The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash (\\\") and backslash as \\\\.\n",
      "\n",
      "`Fixed fields`\n",
      "\n",
      "There are 8 fixed fields per record. All data lines are tab-delimited. In all cases, missing values are specified with a dot (\u201d.\u201d). \n",
      "\n",
      "Fixed fields are:\n",
      "\n",
      "    * CHROM chromosome: an identifier from the reference genome or an angle-bracketed ID String (\"<ID>\") pointing to a contig in the assembly file (cf. the ##assembly line in the header). All entries for a specific CHROM should form a contiguous block within the VCF file. The colon symbol (:) must be absent from all chromosome names to avoid parsing errors when dealing with breakends. (String, no white-space permitted, Required).\n",
      "    * POS position: The reference position, with the `1st base having position 1`. Positions are sorted numerically, in increasing order, within each reference sequence CHROM.   It is permitted to have `multiple records` with the `same POS`. `Telomeres` are indicated by using positions `0` or `N+1`, where N is the length of the corresponding chromosome or contig.   (Integer, Required)\n",
      "    * ID: semi-colon separated list of unique identifiers where available. If this is a dbSNP variant it is encouraged to use the rs number(s). No identifier should be present in more than one data record. If there is no identifier available, then the missing value should be used. (String, no white-space or semi-colons permitted)\n",
      "    * REF reference base(s): Each base must be one of A,C,G,T,N (case insensitive). Multiple bases are permitted. The value in the POS field refers to the position of the first base in the String. For simple insertions and deletions in which either the REF or one of the ALT alleles would otherwise be null/empty, the REF and ALT Strings must include the base before the event (which must be reflected in the POS field), unless the event occurs at position 1 on the contig in which case it must include the base after the event; this padding base is not required (although it is permitted) for e.g. complex substitutions or other events where all alleles have at least one base represented in their Strings.  If any of the ALT alleles is a symbolic allele (an angle-bracketed ID String \"<ID>\") then the padding base is required and POS denotes the coordinate of the base preceding the polymorphism. Tools processing VCF files are not required to preserve case in the allele Strings. (String, Required).\n",
      "    * ALT: comma separated list of alternate non-reference alleles called on at least one of the samples. Options are base Strings made up of the bases A,C,G,T,N, (case insensitive) or an angle-bracketed ID String (\u201d<ID>\u201d) or a breakend replacement string as described in the section on breakends. If there are no alternative alleles, then the missing value should be used.  Tools processing VCF files are not required to preserve case in the allele String, except for IDs, which are case sensitive.  (String; no whitespace, commas, or angle-brackets are permitted in the ID String itself)\n",
      "    * QUAL: phred-scaled quality score for the assertion made in ALT. i.e. -10log_10 prob(call in ALT is wrong). If ALT is \u201d.\u201d (no variant) then this is `-10*log10(p(variant))`, and if ALT is not \u201d.\u201d this is -10log_10 p(no variant). High QUAL scores indicate high confidence calls. Although traditionally people use integer phred scores, this field is permitted to be a floating point to enable higher resolution for low confidence calls if desired.  If unknown, the missing value should be specified. (Numeric)\n",
      "    * FILTER : PASS if this position has passed all filters, i.e. a call is made at this position. Otherwise, if the site has not passed all filters, a semicolon-separated list of codes for filters that fail. e.g. \u201cq10;s50\u201d might indicate that at this site the quality is below 10 and the number of samples with data is below 50% of the total number of samples. \u201c0\u201d is reserved and should not be used as a filter String. If filters have not been applied, then this field should be set to the missing value. (String, no white-space or semi-colons permitted)\n",
      "    * INFO additional information: (String, no white-space, semi-colons, or equals-signs permitted; commas are permitted only as delimiters for lists of values) INFO fields are encoded as a semicolon-separated series of short keys with optional values in the format: <key>=<data>[,data]. Arbitrary keys are permitted, although the following sub-fields are reserved (albeit optional):\n",
      "AA : ancestral allele\n",
      "AC : allele count in genotypes, for each ALT allele, in the same order as listed\uff0c\u8868\u793a\u53d1\u751f\u7a81\u53d8\u7684\u7b49\u4f4d\u57fa\u56e0\u7684\u6570\u76ee\u3002\u5bf9\u4e8e1\u4e2a\u4e8c\u500d\u4f53\u6837\u54c1\u6765\u8bf4\uff0c\u57fa\u56e0\u578b 0/1 \u8868\u793a\u6837\u54c1\u4e3a\u6742\u5408\u7a81\u53d8\uff0cAC\u6570\u4e3a1(\u53cc\u500d\u4f53\u6837\u54c1\u5728\u8be5\u4f4d\u70b9\u53ea\u67091\u4e2a\u7b49\u4f4d\u57fa\u56e0\u53d1\u751f\u4e86\u7a81\u53d8)\uff0cAF\u7684\u9891\u7387\u4e3a0.5(\u53cc\u500d\u4f53\u7684\u6837\u54c1\u5728\u8be5\u4f4d\u70b9\u53ea\u670950%\u7684\u7b49\u4f4d\u57fa\u56e0\u53d1\u751f\u4e86\u7a81\u53d8)\uff0c\u603b\u7684\u7b49\u4f4d\u57fa\u56e0\u4e3a2\uff1b \u57fa\u56e0\u578b 1/1 \u5219\u8868\u793a\u6837\u54c1\u4e3a\u7eaf\u5408\u7a81\u53d8\uff0cAC\u6570\u4e3a2\uff0cAF\u7684\u9891\u7387\u4e3a1\uff0c\u603b\u7684AN\u4e3a2\u3002\u5982\u679c\u6709\u591a\u4e2a\u6837\u54c1\uff0c\u5219\u53e0\u52a0\u8ba1\u7b97\u3002\n",
      "AF : allele frequency for each ALT allele in the same order as listed: use this when estimated from primary data, not called genotypes\uff0c\u8868\u793a\u53d1\u751f\u7a81\u53d8\u7684\u7b49\u4f4d\u57fa\u56e0\u5360\u603b\u7b49\u4f4d\u57fa\u56e0\u7684\u6bd4\u4f8b\n",
      "AN : total number of alleles in called genotypes\n",
      "BaseQRankSum: Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\n",
      "ClippingRankSum: Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\n",
      "FS: Phred-scaled p-value using Fisher's exact test to detect strand bias, \u4f7f\u7528Fisher\u2019s\u7cbe\u786e\u68c0\u9a8c\u6765\u68c0\u6d4b\u94fe\u7a81\u53d8\u7684\u504f\u597d\u6027\u800c\u5f97\u5230\u7684Fhred\u683c\u5f0f\u7684p\u503c\u3002\u8be5\u503c\u8d8a\u5c0f\u8d8a\u597d\u3002\n",
      "MLEAC: Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed.\n",
      "MLEAF: \"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed.\n",
      "MQ: RMS mapping quality, e.g. MQ=52\n",
      "MQ0: Total Mapping Quality Zero Reads, Number of MAPQ == 0 reads covering this record\n",
      "MQRankSum: Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\n",
      "QD: Variant Confidence/Quality by Depth\n",
      "ReadPosRankSum: Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\n",
      "\n",
      "BQ : RMS base quality at this position\n",
      "CIGAR : cigar string describing how to align an alternate allele to the reference allele\n",
      "DB : dbSNP membership\n",
      "DP : combined depth across samples, e.g. DP=154\uff0c\u8be5\u4f4d\u70b9\u7684\u6d4b\u5e8f\u6df1\u5ea6\n",
      "END : end position of the variant described in this record (for use with symbolic alleles)\n",
      "H2 : membership in hapmap2\n",
      "H3 : membership in hapmap3\n",
      "\n",
      "##FORMAT=<ID=AD,Number=.,Type=Integer,Description=>\n",
      "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"\">\n",
      "##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum DP observed within the GVCF block\">\n",
      "##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"\">\n",
      "\n",
      "GT\uff1agenotype; \u6837\u54c1\u7684\u57fa\u56e0\u578b\uff08genotype\uff09\u3002\u4e24\u4e2a\u6570\u5b57\u4e2d\u95f4\u7528\u2019/'\u5206 \u5f00\uff0c\u8fd9\u4e24\u4e2a\u6570\u5b57\u8868\u793a\u53cc\u500d\u4f53\u7684sample\u7684\u57fa\u56e0\u578b\u30020 \u8868\u793a\u6837\u54c1\u4e2d\u6709ref\u7684allele\uff1b 1 \u8868\u793a\u6837\u54c1\u4e2dvariant\u7684allele\uff1b 2\u8868\u793a\u6709\u7b2c\u4e8c\u4e2avariant\u7684allele\u3002\u56e0\u6b64\uff1a 0/0 \u8868\u793asample\u4e2d\u8be5\u4f4d\u70b9\u4e3a\u7eaf\u5408\u7684\uff0c\u548cref\u4e00\u81f4\uff1b 0/1 \u8868\u793asample\u4e2d\u8be5\u4f4d\u70b9\u4e3a\u6742\u5408\u7684\uff0c\u6709ref\u548cvariant\u4e24\u4e2a\u57fa\u56e0\u578b\uff1b 1/1 \u8868\u793asample\u4e2d\u8be5\u4f4d\u70b9\u4e3a\u7eaf\u5408\u7684\uff0c\u548cvariant\u4e00\u81f4\u3002\n",
      "AD: Allelic depths for the ref and alt alleles in the order listed,\u4e3asample\u4e2d\u6bcf\u4e00\u79cd\u7b49\u4f4d\u57fa\u56e0\u7684\u5e8f\u5217\u8986\u76d6\u5ea6,\u5728\u4e8c\u500d\u4f53\u4e2a\u4f53\u4e2d\u5219\u662f\u7528\u9017\u53f7\u5206\u5272\u7684\u4e24\u4e2a\u503c\uff0c\u524d\u8005\u5bf9\u5e94\u53c2\u8003\u57fa\u56e0\u7ec4\u57fa\u56e0\u578b\uff0c\u540e\u8005\u5bf9\u5e94\u7a81\u53d8\u4f53\u57fa\u56e0\u578b\n",
      "DP\uff1aApproximate read depth (reads with MQ=255 or with bad mates are filtered), \u4e3asample\u4e2d\u8be5\u4f4d\u70b9\u7684\u8986\u76d6\u5ea6\u3002\n",
      "GQ\uff1a\u57fa\u56e0\u578b\u7684\u8d28\u91cf\u503c(Genotype Quality)\u3002Phred\u683c\u5f0f(Phred_scaled)\u7684\u8d28\u91cf\u503c\uff0c\u8868\u793a\u5728\u8be5\u4f4d\u70b9\u8be5\u57fa\u56e0\u578b\u5b58\u5728\u7684\u53ef\u80fd\u6027\uff1b\u8be5\u503c\u8d8a\u9ad8\uff0c\u5219Genotype\u7684\u53ef\u80fd\u6027\u8d8a \u5927\uff1b\u8ba1\u7b97\u65b9\u6cd5\uff1aPhred\u503c = -10 * log (1-p) p\u4e3a\u57fa\u56e0\u578b\u5b58\u5728\u7684\u6982\u7387\u3002\n",
      "PL\uff1aNormalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\uff0c\u6307\u5b9a\u7684\u4e09\u79cd\u57fa\u56e0\u578b\u7684\u8d28\u91cf\u503c(provieds the likelihoods of the given genotypes)\u3002\u8fd9\u4e09\u79cd\u6307\u5b9a\u7684\u57fa\u56e0\u578b\u4e3a(0/0,0/1,1/1)\uff0c\u8fd9\u4e09\u79cd\u57fa\u56e0\u578b\u7684\u6982\u7387\u603b\u548c\u4e3a1\u3002\u548c\u4e4b\u524d\u4e0d\u4e00\u81f4\uff0c\u8be5\u503c\u8d8a\u5927\uff0c\u8868\u660e\u4e3a\u8be5\u79cd\u57fa\u56e0\u578b\u7684\u53ef\u80fd \u6027\u8d8a\u5c0f\u3002 Phred\u503c = -10 * log (p) p\u4e3a\u57fa\u56e0\u578b\u5b58\u5728\u7684\u6982\u7387\u3002\n",
      "\n",
      "\n",
      "MQ0 : \n",
      "NS : Number of samples with data\n",
      "SB : strand bias at this position\n",
      "SOMATIC : indicates that the record is a somatic mutation, for cancer genomics\n",
      "VALIDATED : validated by follow-up experiment\n",
      "1000G : membership in 1000 Genomes\n",
      "The exact format of each INFO sub-field should be specified in the meta-information (as described above).\n",
      "\n",
      "Example for an INFO field: DP=154;MQ=52;H2. Keys without corresponding values are allowed in order to indicate group membership (e.g. H2 indicates the SNP is found in HapMap 2). It is not necessary to list all the properties that a site does NOT have, by e.g. H2=0.\n",
      "\n",
      "See below for additional reserved INFO sub-fields used to encode structural variants.\n",
      "\n",
      "CHROM \u548c POS\uff1a\u4ee3\u8868\u53c2\u8003\u5e8f\u5217\u540d\u548cvariant\u7684\u4f4d\u7f6e\uff1b\u5982\u679c\u662fINDEL\u7684\u8bdd\uff0c\u4f4d\u7f6e\u662fINDEL\u7684\u7b2c\u4e00\u4e2a\u78b1\u57fa\u4f4d\u7f6e\u3002\n",
      "ID\uff1avariant\u7684ID\u3002\u6bd4\u5982\u5728dbSNP\u4e2d\u6709\u8be5SNP\u7684id\uff0c\u5219\u4f1a\u5728\u6b64\u884c\u7ed9\u51fa\uff1b\u82e5\u6ca1\u6709\uff0c\u5219\u7528\u2019.'\u8868\u793a\u5176\u4e3a\u4e00\u4e2anovel variant\u3002\n",
      "REF \u548c ALT\uff1a\u53c2\u8003\u5e8f\u5217\u7684\u78b1\u57fa \u548c Variant\u7684\u78b1\u57fa\u3002\n",
      "QUAL\uff1aPhred\u683c\u5f0f(Phred_scaled)\u7684\u8d28\u91cf\u503c\uff0c\u8868 \u793a\u5728\u8be5\u4f4d\u70b9\u5b58\u5728variant\u7684\u53ef\u80fd\u6027\uff1b\u8be5\u503c\u8d8a\u9ad8\uff0c\u5219variant\u7684\u53ef\u80fd\u6027\u8d8a\u5927\uff1b\u8ba1\u7b97\u65b9\u6cd5\uff1aPhred\u503c = -10 * log (1-p) p\u4e3avariant\u5b58\u5728\u7684\u6982\u7387; \u901a\u8fc7\u8ba1\u7b97\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\u503c\u4e3a10\u7684\u8868\u793a\u9519\u8bef\u6982\u7387\u4e3a0.1\uff0c\u8be5\u4f4d\u70b9\u4e3avariant\u7684\u6982\u7387\u4e3a90%\u3002\n",
      "FILTER\uff1a\u4f7f\u7528\u4e0a\u4e00\u4e2aQUAL\u503c\u6765\u8fdb\u884c\u8fc7\u6ee4\u7684\u8bdd\uff0c\u662f\u4e0d\u591f\u7684\u3002GATK\u80fd\u4f7f\u7528\u5176\u5b83\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u8fc7\u6ee4\uff0c\u8fc7\u6ee4\u7ed3\u679c\u4e2d\u901a\u8fc7\u5219\u8be5\u503c\u4e3a\u201dPASS\u201d;\u82e5variant\u4e0d\u53ef\u9760\uff0c\u5219\u8be5\u9879\u4e0d\u4e3a\u201dPASS\u201d\u6216\u201d.\u201d\u3002\n",
      "INFO\uff1a \u8fd9\u4e00\u884c\u662fvariant\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u5185\u5bb9\u5f88\u591a\uff0c\u4ee5\u4e0b\u518d\u5177\u4f53\u8be6\u8ff0\u3002\n",
      "FORMAT \u548c NA12878\uff1a\u8fd9\u4e24\u884c\u5408\u8d77\u6765\u63d0\u4f9b\u4e86\u2019NA12878\u2032\u8fd9\u4e2asample\u7684\u57fa\u56e0\u578b\u7684\u4fe1\u606f\u3002\u2019NA12878\u2032\u4ee3\u8868\u8fd9\u8be5\u540d\u79f0\u7684\u6837\u54c1\uff0c\u662f\u7531BAM\u6587\u4ef6\u4e2d\u7684@RG\u4e0b\u7684 SM \u6807\u7b7e\u51b3\u5b9a\u7684\u3002\n",
      "\n",
      "\n",
      "\n",
      "Dels\uff1aFraction of Reads Containing Spanning Deletions\u3002\u8fdb\u884cSNP\u548cINDEL calling\u7684\u7ed3\u679c\u4e2d\uff0c\u6709\u8be5TAG\u5e76\u4e14\u503c\u4e3a0\u8868\u793a\u8be5\u4f4d\u70b9\u4e3aSNP\uff0c\u6ca1\u6709\u5219\u4e3aINDEL\u3002\n",
      "FS\uff1a\u4f7f\u7528Fisher\u2019s\u7cbe\u786e\u68c0\u9a8c\u6765\u68c0\u6d4bstrand bias\u800c\u5f97\u5230\u7684Fhred\u683c\u5f0f\u7684p\u503c\u3002\u8be5\u503c\u8d8a\u5c0f\u8d8a\u597d\u3002\u4e00\u822c\u8fdb\u884cfilter\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u8bbe\u7f6e FS < 10\uff5e20\u3002\n",
      "\n",
      "```\n",
      "CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  LJR     LSQ\n",
      "chr1    13273   .       G       C       43.44   .       AC=1;AF=0.250;AN=4;BaseQRankSum=1.22;ClippingRankSum=0.322;DP=11;FS=0.000;MLEAC=1;MLEAF=0.250;MQ=29.18;MQ0=0;MQRankSum=0.322;QD=5.43;ReadPosRankSum=-3.220e-01  GT:AD:DP:GQ:PL  0/1:5,3:8:72:72,0,130   0/0:.:3:6:0,6,90\n",
      "chr1    69511   .       A       G       2953.20 .       AC=4;AF=1.00;AN=4;DP=97;FS=0.000;MLEAC=4;MLEAF=1.00;MQ=34.63;MQ0=0;QD=30.45     GT:AD:DP:GQ:PL  1/1:0,50:50:99:1512,150,0       1/1:0,47:47:99:1468,141,0\n",
      "chr1    139213  .       A       G       139.44  .       AC=2;AF=0.500;AN=4;BaseQRankSum=1.73;ClippingRankSum=-6.670e-01;DP=25;FS=0.000;MLEAC=2;MLEAF=0.500;MQ=29.56;MQ0=0;MQRankSum=1.53;QD=5.58;ReadPosRankSum=1.30    GT:AD:DP:GQ:PL  0/1:9,5:14:99:134,0,260 0/1:9,2:11:34:34,0,468\n",
      "```\n",
      "\n",
      "*Ref*:\n",
      "\n",
      "    * http://gatkforums.broadinstitute.org/discussion/4017/what-is-a-gvcf-and-how-is-it-different-from-a-regular-vcf\n",
      "    * http://blog.sina.com.cn/s/blog_74cbb8e80101f8ic.html\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SNP filtering (hard filter)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Apply hard filters to a variant callset that is too small for VQSR or for which truth/training sets are not available.\n",
      "* http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Filtering recommendations for SNPs:\n",
      "    * QD < 2.0\n",
      "    * MQ < 40.0\n",
      "    * FS > 60.0\n",
      "    * HaplotypeScore > 13.0\n",
      "    * MQRankSum < -12.5\n",
      "    * ReadPosRankSum < -8.0\n",
      "* Filtering recommendations for indels:\n",
      "    * QD < 2.0\n",
      "    * ReadPosRankSum < -20.0\n",
      "    * InbreedingCoeff < -0.8\n",
      "    * FS > 200.0\n",
      "* And now some more IMPORTANT caveats (don't skip this!)\n",
      "\n",
      "    * The `InbreedingCoeff` statistic is a population-level calculation that is only available with `10 or more samples`. If you have fewer samples you will need to omit that particular filter statement.\n",
      "\n",
      "    * For shallow-coverage (<10x), it is virtually impossible to use manual filtering to reliably separate true positives from false positives. You really, really, really should use the protocol involving variant quality score recalibration. If you can't do that, maybe you need to take a long hard look at your experimental design. In any case you're probably in for a world of pain.\n",
      "\n",
      "    * The maximum `DP` (depth) filter only applies to whole genome data, where the probability of a site having exactly N reads given an average coverage of M is a well-behaved function. First principles suggest this should be a binomial sampling but in practice it is more a Gaussian distribution. Regardless, the DP threshold should be set a 5 or 6 sigma from the mean coverage across all samples, so that the DP > X threshold eliminates sites with excessive coverage caused by alignment artifacts. Note that for exomes, a straight DP filter shouldn't be used because the relationship between misalignments and depth isn't clear for capture data.\n",
      "\n",
      "* Ref http://www.broadinstitute.org/gatk/guide/article?id=3225"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "#For Exomse-Seq\n",
      "\n",
      "#Extract the SNPs from the call set\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T SelectVariants \\\n",
      "    -R hg19.fasta -selectType SNP -V Exosome.genotypeGVCF.vcf -o Exosome.genotypeGVCF.SNPs.vcf \\\n",
      "    >>hard_filter.log 2>&1\n",
      "#Determine and apply parameter for filtering SNPs\n",
      "\n",
      "# SNPs matching any of these conditions will be considered bad and filtered out, \n",
      "# i.e. marked FILTER in the output VCF file. \n",
      "# The program will specify which parameter was chiefly responsible for the exclusion \n",
      "# of the SNP using the culprit annotation. \n",
      "# SNPs that do not match any of these conditions will be considered good and marked PASS \n",
      "# in the output VCF file.\n",
      "\n",
      "# QualByDepth (QD) 2.0\n",
      "#    This is the variant confidence (from the QUAL field) divided by the unfiltered depth \n",
      "#    of non-reference samples.\n",
      "\n",
      "# FisherStrand (FS) 60.0\n",
      "#    Phred-scaled p-value using Fisher\u2019s Exact Test to detect strand bias \n",
      "#    (the variation being seen on only the forward or only the reverse strand) in the reads. \n",
      "#    More bias is indicative of false positive calls.\n",
      "\n",
      "# RMSMappingQuality (MQ) 40.0\n",
      "#    This is the Root Mean Square of the mapping quality of the reads across all samples.\n",
      "\n",
      "# HaplotypeScore 13.0\n",
      "#    This is the consistency of the site with two (and only two) segregating haplotypes. \n",
      "#    Note that this is not applicable for calls made using the \n",
      "#    UnifiedGenotyper on non-diploid organisms.\n",
      "\n",
      "# MappingQualityRankSumTest (MQRankSum) 12.5\n",
      "#    This is the u-based z-approximation from the Mann-Whitney Rank Sum Test \n",
      "#    for mapping qualities (reads with ref bases vs. those with the alternate allele). \n",
      "#    Note that the mapping quality rank sum test can not be calculated for \n",
      "#    sites without a mixture of reads showing both the reference and alternate alleles, \n",
      "#    i.e. this will only be applied to heterozygous calls.\n",
      "\n",
      "# ReadPosRankSumTest (ReadPosRankSum) 8.0\n",
      "#    This is the u-based z-approximation from the Mann-Whitney Rank Sum Test for \n",
      "#    the distance from the end of the read for reads with the alternate allele. \n",
      "#    If the alternate allele is only seen near the ends of reads, this is indicative of error. \n",
      "#    Note that the read position rank sum test can not be calculated for \n",
      "#    sites without a mixture of reads showing both the reference and alternate alleles, \n",
      "#    i.e. this will only be applied to heterozygous calls.\n",
      "\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantFiltration \\\n",
      "    -R hg19.fasta \\\n",
      "    --filterExpression \"QD < 2.0\" --filterName \"LowQualByDepth\" \\\n",
      "    --filterExpression \"FS > 60.0\" --filterName \"HighFisherStrand\" \\\n",
      "    --filterExpression \"MQ < 40.0\" --filterName \"LowRMSMappingQuality\" \\\n",
      "    --filterExpression \"HaplotypeScore > 13.0\" --filterName \"HighHaplotypeScore\" \\\n",
      "    --filterExpression \"MappingQualityRankSum < -12.5\" --filterName \"LowMappingQualityRankSum\" \\\n",
      "    --filterExpression \"ReadPosRankSum < -8.0\" --filterName \"HighReadPosRankSum\" \\\n",
      "    -V Exosome.genotypeGVCF.SNPs.vcf -o Exosome.genotypeGVCF.SNPs.hardfilter.vcf \\\n",
      "    >>hard_filter.log 2>&1\n",
      "\n",
      "# Extract the indels from the call set\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T SelectVariants \\\n",
      "    -R hg19.fasta -selectType INDEL -V Exosome.genotypeGVCF.vcf \\\n",
      "    -o Exosome.genotypeGVCF.INDEL.vcf >>hard_filter.log 2>&1\n",
      "\n",
      "# Determine and apply parameter for filtering indels\n",
      "\n",
      "# Indels matching any of these conditions will be considered bad and filtered out, \n",
      "# i.e. marked FILTER in the output VCF file. The program will specify which parameter was \n",
      "# chiefly responsible for the exclusion of the indel using the culprit annotation. \n",
      "# Indels that do not match any of these conditions will be considered good and marked PASS \n",
      "# in the output VCF file.\n",
      "\n",
      "# QualByDepth (QD) 2.0\n",
      "#    This is the variant confidence (from the QUAL field) divided by the unfiltered depth \n",
      "#    of non-reference samples.\n",
      "\n",
      "# FisherStrand (FS) 200.0\n",
      "#    Phred-scaled p-value using Fisher\u2019s Exact Test to detect strand bias \n",
      "#    (the variation being seen on only the forward or only the reverse strand) in the reads. \n",
      "#    More bias is indicative of false positive calls.\n",
      "\n",
      "# ReadPosRankSumTest (ReadPosRankSum) 20.0\n",
      "#    This is the u-based z-approximation from the Mann-Whitney Rank Sum Test for the distance \n",
      "#    from the end of the read for reads with the alternate allele. \n",
      "#    If the alternate allele is only seen near the ends of reads, this is indicative of error. \n",
      "#    Note that the read position rank sum test can not be calculated for \n",
      "#    sites without a mixture of reads showing both the reference and alternate alleles, \n",
      "#    i.e. this will only be applied to heterozygous calls.\n",
      "\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantFiltration \\\n",
      "    -R hg19.fasta \\\n",
      "    --filterExpression \"QD < 2.0\" --filterName \"LowQualByDepth\" \\\n",
      "    --filterExpression \"FS > 200.0\" --filterName \"HighFisherStrand\" \\\n",
      "    --filterExpression \"ReadPosRankSum < -20.0\" --filterName \"HighReadPosRankSum\" \\\n",
      "    -V Exosome.genotypeGVCF.INDEL.vcf -o Exosome.genotypeGVCF.INDEL.hardfilter.vcf \\\n",
      "    >>hard_filter.log 2>&1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SNP filtering (VQSR)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Recalibrate variant quality scores and produce a callset filtered for the desired levels of sensitivity and specificity.\n",
      "\n",
      "**For SNPs**\n",
      "\n",
      "* a. Specify which call sets the program should use as resources to build the recalibration model\n",
      "\n",
      "    * For each training set, we use key-value tags to qualify whether the set contains known sites, training sites, and/or truth sites. We also use a tag to specify the prior likelihood that those sites are true (using the Phred scale).\n",
      "\n",
      "    * True sites training resource: `HapMap`\n",
      "        * This resource is a SNP call set that has been validated to a very high degree of confidence. The program will consider that the variants in this resource are representative of true sites (`truth=true`), and will use them to train the recalibration model (`training=true`). We will also use these sites later on to choose a threshold for filtering variants based on sensitivity to truth sites. The prior likelihood we assign to these variants is Q15 (96.84%).\n",
      "\n",
      "    * True sites training resource: `Omni`\n",
      "        * This resource is a set of polymorphic SNP sites produced by the Omni genotyping array. The program will consider that the variants in this resource are representative of true sites (`truth=true`), and will use them to train the recalibration model (`training=true`). The prior likelihood we assign to these variants is Q12 (93.69%).\n",
      "\n",
      "    * Non-true sites training resource: `1000G`\n",
      "        * This resource is a set of high-confidence SNP sites produced by the 1000 Genomes Project. The program will consider that the variants in this resource may contain true variants as well as false positives (`truth=false`), and will use them to train the recalibration model (`training=true`). The prior likelihood we assign to these variants is Q10 (%).\n",
      "\n",
      "    * Known sites resource, not used in training: `dbSNP`\n",
      "        * This resource is a SNP call set that has not been validated to a high degree of confidence (`truth=false`). The program will not use the variants in this resource to train the recalibration model (`training=false`). However, the program will use these to stratify output metrics such as `Ti/Tv` ratio by whether variants are present in dbsnp or not (`known=true`). The prior likelihood we assign to these variants is Q2 (36.90%).\n",
      "\n",
      "    * \tThe default prior likelihood assigned to all other variants is Q2 (36.90%). This low value reflects the fact that the philosophy of the GATK callers is to produce a large, highly sensitive callset that needs to be heavily refined through additional filtering.\n",
      "\n",
      "* b. Specify which annotations the program should use to evaluate the likelihood of Indels being real\n",
      "    * These annotations are included in the information generated for each variant call by the caller. If an annotation is missing (typically because it was omitted from the calling command) it can be added using the VariantAnnotator tool.\n",
      "\n",
      "    * Coverage (DP)\n",
      "        * Total (unfiltered) depth of coverage.\n",
      "\n",
      "    * QualByDepth (QD)\n",
      "        * Variant confidence (from the QUAL field) / unfiltered depth of non-reference samples.\n",
      "\n",
      "    * FisherStrand (FS)\n",
      "        * Phred-scaled p-value using Fisher's Exact Test to detect strand bias (the variation being seen on only the forward or only the reverse strand) in the reads. More bias is indicative of false positive calls.\n",
      "\n",
      "    * MappingQualityRankSumTest (MQRankSum)\n",
      "        * The u-based z-approximation from the Mann-Whitney Rank Sum Test for mapping qualities (reads with ref bases vs. those with the alternate allele). Note that the mapping quality rank sum test can not be calculated for sites without a mixture of reads showing both the reference and alternate alleles.\n",
      "\n",
      "    * ReadPosRankSumTest (ReadPosRankSum)\n",
      "        * The u-based z-approximation from the Mann-Whitney Rank Sum Test for the distance from the end of the read for reads with the alternate allele. If the alternate allele is only seen near the ends of reads, this is indicative of error. Note that the read position rank sum test can not be calculated for sites without a mixture of reads showing both the reference and alternate alleles.\n",
      "\n",
      "* c. Specify the desired truth sensitivity threshold values that the program should use to generate tranches\n",
      "    * First tranche threshold 100.0\n",
      "\n",
      "    * Second tranche threshold 99.9\n",
      "\n",
      "    * Third tranche threshold 99.0\n",
      "\n",
      "    * Fourth tranche threshold 90.0\n",
      "\n",
      "    * Tranches are essentially slices of variants, ranked by VQSLOD, bounded by the threshold values specified in this step. The threshold values themselves refer to the sensitivity we can obtain when we apply them to the call sets that the program uses to train the model. The idea is that the lowest tranche is highly specific but less sensitive (there are very few false positives but potentially many false negatives, i.e. missing calls), and each subsequent tranche in turn introduces additional true positive calls along with a growing number of false positive calls. This allows us to filter variants based on how sensitive we want the call set to be, rather than applying hard filters and then only evaluating how sensitive the call set is using post hoc methods.\n",
      "\n",
      "**For INDELs**\n",
      "\n",
      "* a. Specify which call sets the program should use as resources to build the recalibration model\n",
      "    * For each training set, we use key-value tags to qualify whether the set contains known sites, training sites, and/or truth sites. We also use a tag to specify the prior likelihood that those sites are true (using the Phred scale).\n",
      "\n",
      "    * Known and true sites training resource: `Mills`\n",
      "        * This resource is an Indel call set that has been validated to a high degree of confidence. The program will consider that the variants in this resource are representative of true sites (`truth=true`), and will use them to train the recalibration model (`training=true`). The prior likelihood we assign to these variants is Q12 (93.69%).\n",
      "\n",
      "    * The default prior likelihood assigned to all other variants is Q2 (36.90%). This low value reflects the fact that the philosophy of the GATK callers is to produce a large, highly sensitive callset that needs to be heavily refined through additional filtering.\n",
      "\n",
      "* b. Specify which annotations the program should use to evaluate the likelihood of Indels being real\n",
      "    * These annotations are included in the information generated for each variant call by the caller. If an annotation is missing (typically because it was omitted from the calling command) it can be added using the VariantAnnotator tool.\n",
      "\n",
      "    * Coverage (DP)\n",
      "        * Total (unfiltered) depth of coverage.\n",
      "\n",
      "    * FisherStrand (FS)\n",
      "        * Phred-scaled p-value using Fisher's Exact Test to detect strand bias (the variation being seen on only the forward or only the reverse strand) in the reads. More bias is indicative of false positive calls.\n",
      "\n",
      "    * MappingQualityRankSumTest (MQRankSum)\n",
      "        * The u-based z-approximation from the Mann-Whitney Rank Sum Test for mapping qualities (reads with ref bases vs. those with the alternate allele). Note that the mapping quality rank sum test can not be calculated for sites without a mixture of reads showing both the reference and alternate alleles.\n",
      "\n",
      "    * ReadPosRankSumTest (ReadPosRankSum)\n",
      "        * The u-based z-approximation from the Mann-Whitney Rank Sum Test for the distance from the end of the read for reads with the alternate allele. If the alternate allele is only seen near the ends of reads, this is indicative of error. Note that the read position rank sum test can not be calculated for sites without a mixture of reads showing both the reference and alternate alleles.\n",
      "\n",
      "* c. Specify the desired truth sensitivity threshold values that the program should use to generate tranches\n",
      "    * First tranche threshold 100.0\n",
      "\n",
      "    * Second tranche threshold 99.9\n",
      "\n",
      "    * Third tranche threshold 99.0\n",
      "\n",
      "    * Fourth tranche threshold 90.0\n",
      "\n",
      "    * Tranches are essentially slices of variants, ranked by VQSLOD, bounded by the threshold values specified in this step. The threshold values themselves refer to the sensitivity we can obtain when we apply them to the call sets that the program uses to train the model. The idea is that the lowest tranche is highly specific but less sensitive (there are very few false positives but potentially many false negatives, i.e. missing calls), and each subsequent tranche in turn introduces additional true positive calls along with a growing number of false positive calls. This allows us to filter variants based on how sensitive we want the call set to be, rather than applying hard filters and then only evaluating how sensitive the call set is using post hoc methods.\n",
      "\n",
      "* d. Determine additional model parameters\n",
      "    * Maximum number of Gaussians (-maxGaussians) 4\n",
      "        * This is the maximum number of Gaussians (i.e. clusters of variants that have similar properties) that the program should try to identify when it runs the variational Bayes algorithm that underlies the machine learning method. In essence, this limits the number of different \u201dprofiles\u201d of variants that the program will try to identify. This number should only be increased for datasets that include very many variants."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Whole-Genome-Seq\u4f7f\u7528\u7684\u53c2\u6570\u548c\u9700\u8981\u6ce8\u610f\u7684\u4e8b\u9879"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#Whole-Genome-Seq for more than 9 samples (-an InbreedingCoeff)\n",
      "#VariantRecalibrator for SNP\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantRecalibrator \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.vcf -mode SNP \\\n",
      "    -resource:hapmap,known=false,training=true,truth=true,prior=15.0 hapmap_3.3.hg19.vcf \\\n",
      "    -resource:omni,known=false,training=true,truth=true,prior=12.0 1000G_omni2.5.hg19.vcf \\\n",
      "    -resource:1000G,known=false,training=true,truth=false,prior=10.0 1000G_phase1.snps.high_confidence.hg19.vcf \\\n",
      "    -resource:dbsnp,known=true,training=false,truth=false,prior=2.0 dbsnp_138.hg19.vcf \\\n",
      "    -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an DP -an InbreedingCoeff \\\n",
      "    -recalFile Exosome.genotypeGVCF.SNPs.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs.vqsr_tranches \\\n",
      "    -rscriptFile Exosome.genotypeGVCF.SNPs.plots.r \\\n",
      "    -tranche 100.0 -tranche 99.9 -tranche 99.0 -tranche 90.0 -nt 10 >>vqsr_filter.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T ApplyRecalibration \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.vcf -mode SNP \\\n",
      "    -ts_filter_level 99.5 -recalFile Exosome.genotypeGVCF.SNPs.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs.vqsr_tranches \\\n",
      "    -o Exosome.genotypeGVCF.SNPs.vqsr.vcf >>vqsr_filter.log 2>&1\n",
      "\n",
      "#VariantRecalibrator for INDELS\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantRecalibrator \\\n",
      "    -R hg19.fasta -mode INDEL -input Exosome.genotypeGVCF.SNPs.vqsr.vcf --maxGaussians 4 \\\n",
      "    -resource:mills,known=false,training=true,truth=true,prior=12.0 Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -resource:dbsnp,known=true,training=false,truth=false,prior=2.0 dbsnp_138.hg19.vcf \\\n",
      "    -an QD -an FS -an ReadPosRankSum -an MQRankSum -an DP -an InbreedingCoeff \\\n",
      "    -recalFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_tranches \\\n",
      "    -rscriptFile Exosome.genotypeGVCF.SNPs_INDEL.plots.r -nt 10  >>vqsr_filter.log 2>&1\n",
      "    \n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T ApplyRecalibration \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.SNPs.vqsr.vcf -mode INDEL \\\n",
      "    -ts_filter_level 99.0 -recalFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_tranches \\\n",
      "    -o Exosome.genotypeGVCF.SNPs_INDEL.vqsr.vcf >>vqsr_filter.log 2>&1; \\\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exome-Seq\u4f7f\u7528\u7684\u53c2\u6570\u548c\u9700\u8981\u6ce8\u610f\u7684\u4e8b\u9879"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Depth of coverage (the DP annotation invoked by Coverage) should **not** be used when working with **exome** datasets since there is extreme variation in the depth to which targets are captured! In whole genome experiments this variation is indicative of error but that is not the case in capture experiments.\n",
      "* The *InbreedingCoeff* is a population level statistic that requires at least **10** samples in order to be computed. For projects with fewer samples please omit this annotation from the command line.\n",
      "* In our testing we've found that in order to achieve the best exome results one needs to use an exome SNP and/or indel callset with at least **30** samples. For users with experiments containing fewer exome samples there are several options to explore:\n",
      "\n",
      "    * Add additional samples for variant calling, either by sequencing additional samples or using publicly available exome bams from the 1000 Genomes Project (this option is used by the Broad exome production pipeline)\n",
      "    * Use the VQSR with the smaller variant callset but experiment with the precise argument settings (try adding --maxGaussians 4 to your command line, for example)\n",
      "\n",
      "\n",
      "* \u53c2\u8003\u8d44\u6599\n",
      "    * http://gatkforums.broadinstitute.org/discussion/1259/what-vqsr-training-sets-arguments-should-i-use-for-my-specific-project \n",
      "    * http://gatkforums.broadinstitute.org/discussion/1783/variantrecalibrator-creating-a-truth-data-set\n",
      "    * http://www.broadinstitute.org/gatk/guide/article?id=39\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#Exomse-Seq for more than 9 samples (-an InbreedingCoeff)\n",
      "#VariantRecalibrator for SNP\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantRecalibrator \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.vcf -mode SNP \\\n",
      "    -resource:hapmap,known=false,training=true,truth=true,prior=15.0 hapmap_3.3.hg19.vcf \\\n",
      "    -resource:omni,known=false,training=true,truth=true,prior=12.0 1000G_omni2.5.hg19.vcf \\\n",
      "    -resource:1000G,known=false,training=true,truth=false,prior=10.0 1000G_phase1.snps.high_confidence.hg19.vcf \\\n",
      "    -resource:dbsnp,known=true,training=false,truth=false,prior=2.0 dbsnp_138.hg19.vcf \\\n",
      "    -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an InbreedingCoeff \\\n",
      "    -recalFile Exosome.genotypeGVCF.SNPs.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs.vqsr_tranches \\\n",
      "    -rscriptFile Exosome.genotypeGVCF.SNPs.plots.r \\\n",
      "    -tranche 100.0 -tranche 99.9 -tranche 99.0 -tranche 90.0 -nt 10 >>vqsr_filter.log 2>&1\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T ApplyRecalibration \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.vcf -mode SNP \\\n",
      "    -ts_filter_level 99.5 -recalFile Exosome.genotypeGVCF.SNPs.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs.vqsr_tranches \\\n",
      "    -o Exosome.genotypeGVCF.SNPs.vqsr.vcf >>vqsr_filter.log 2>&1\n",
      "\n",
      "#VariantRecalibrator for INDELS\n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T VariantRecalibrator \\\n",
      "    -R hg19.fasta -mode INDEL -input Exosome.genotypeGVCF.SNPs.vqsr.vcf --maxGaussians 4 \\\n",
      "    -resource:mills,known=false,training=true,truth=true,prior=12.0 Mills_and_1000G_gold_standard.indels.hg19.vcf \\\n",
      "    -resource:dbsnp,known=true,training=false,truth=false,prior=2.0 dbsnp_138.hg19.vcf \\\n",
      "    -an QD -an FS -an ReadPosRankSum -an MQRankSum -an InbreedingCoeff \\\n",
      "    -recalFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_tranches \\\n",
      "    -rscriptFile Exosome.genotypeGVCF.SNPs_INDEL.plots.r -nt 10  >>vqsr_filter.log 2>&1\n",
      "    \n",
      "java -Xmx8g -Djava.io.tmpdir=/tmp -jar ~/GATK/GenomeAnalysisTK.jar -T ApplyRecalibration \\\n",
      "    -R hg19.fasta -input Exosome.genotypeGVCF.SNPs.vqsr.vcf -mode INDEL \\\n",
      "    -ts_filter_level 99.0 -recalFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_recal \\\n",
      "    -tranchesFile Exosome.genotypeGVCF.SNPs_INDEL.vqsr_tranches \\\n",
      "    -o Exosome.genotypeGVCF.SNPs_INDEL.vqsr.vcf >>vqsr_filter.log 2>&1; \\\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "\u53c2\u6570\u89e3\u91ca"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* `-ts_filter_level`: We typically seek to achieve 99.5% sensitivity to the accessible truth sites for SNPs and 99.0% for INDELs.\n",
      "* `-tranche`: The default values are 100.0, 99.9, 99.0, and 90.0"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "\u9519\u8bef\u7c7b\u578b\u548c\u89e3\u51b3\u65b9\u5f0f"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* ERROR MESSAGE: Timeout of 30000 milliseconds was reached while trying to acquire a lock on file 1000G_phase1.snps.high_confidence.hg19.vcf.idx. Since the GATK uses non-blocking lock acquisition calls that are not supposed to wait, this implies a problem with the file locking support in your operating system.\n",
      "    * \u6dfb\u52a0\u53c2\u6570 --disable_auto_index_creation_and_locking_when_reading_rods \n",
      "        * [This parameter disables index auto-creation and related file locking when reading vcfs. If all index files are pre-existing, and no concurrent processes will ever update any of the indices, it should be safe to use this argument.]([http://gatkforums.broadinstitute.org/discussion/1252/unifiedgenotyper-gets-hung-waiting-for-file-lock)\n",
      "\n",
      "* ERROR MESSAGE: Bad input: Values for InbreedingCoeff annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.\n",
      "    * \u5982\u679c\u4f60\u7684\u6837\u54c1\u4e0a\u5c11\u4e8e10\u4e2a\uff0c\u8bf7\u53bb\u6389\u53c2\u6570 -an InbreedingCoeff\n",
      "    * \u5426\u5219\uff0c\u8bf7\u5c1d\u8bd5\u4f7f\u7528 VariantAnnotator\n",
      "        * http://gatkforums.broadinstitute.org/discussion/1406/error-values-for-inbreedingcoeff-annotation-not-detected-for-any-training-variant-in-the-input"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SNP\u6ce8\u91ca"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Annovar\u6ce8\u91ca"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Annovar\u5b89\u88c5\u548c\u6570\u636e\u5e93\u4e0b\u8f7d"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "wget http://www.openbioinformatics.org/annovar/download/mP628pfL21/annovar.latest.tar.gz\n",
      "tar xvzf annovar.latest.tar.gz\n",
      "echo \"export \\${PATH}=\\${PATH}:`pwd`/annovar\" >>~/.bashsrc\n",
      "source ~/.bashrc\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```make\n",
      "cat <<END >Makefile\n",
      "#makefile\u8bed\u53e5\n",
      "annovar_dir=$(dir $(shell which annotate_variation.pl))\n",
      "\n",
      "download_annovar_db:\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            cytoBand $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            phastConsElements46way $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            1000g2012apr $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            genomicSuperDups $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar refGene $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar snp138 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar ljb23_all $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar esp6500si_all $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar cg46 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar cg69 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar cosmic68 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar cosmic68wgs $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar cadd $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar caddgt20 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar caddgt10 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar gerp++gt2 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar gerp++elem $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar ensGene $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar knownGene $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar popfreq_all $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar clinvar_20140702 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar nci60 $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar snp138NonFlagged $(annovar_dir)humandb/\n",
      "        annotate_variation.pl -downdb -buildver hg19 \\\n",
      "            -webfrom annovar 1000g2012apr $(annovar_dir)humandb/\n",
      "END\n",
      "make download_annovar_db\n",
      "```"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Annovar\u6ce8\u91ca"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#For hard-filter\n",
      "#Convert format\n",
      "convert2annovar.pl --format vcf4 Exosome.genotypeGVCF.SNPs.hardfilter.vcf \\\n",
      "    --outfile Exosome.genotypeGVCF.SNPs.hardfilter.vcf.ai \\\n",
      "    --allsample --includeinfo --comment --withzyg\n",
      "convert2annovar.pl --format vcf4 Exosome.genotypeGVCF.INDEL.hardfilter.vcf \\\n",
      "    --outfile Exosome.genotypeGVCF.INDEL.hardfilter.vcf.ai \\\n",
      "    --allsample --includeinfo --comment --withzyg\n",
      "#Begin annotation\n",
      "table_annovar.pl --remove --buildver hg19 \\\n",
      "    --outfile Exosome.genotypeGVCF.SNPs.hardfilter.vcf.avoutput --nastring . \\\n",
      "    --protocol refGene,cytoBand,genomicSuperDups,esp6500si_all,1000g2012apr_all,snp138,ljb23_all \\\n",
      "    --operation g,r,r,f,f,f,f \\\n",
      "    Exosome.genotypeGVCF.SNPs.hardfilter.vcf.ai.NA19129.avinput humandb/\n",
      "table_annovar.pl --remove --buildver hg19 \\\n",
      "    --outfile Exosome.genotypeGVCF.INDEL.hardfilter.vcf.avoutput --nastring . \\\n",
      "    --protocol refGene,cytoBand,genomicSuperDups,esp6500si_all,1000g2012apr_all,snp138,ljb23_all \\\n",
      "    --operation g,r,r,f,f,f,f \\\n",
      "    Exosome.genotypeGVCF.INDEL.hardfilter.vcf.ai.NA19129.avinput humandb/\n",
      "\n",
      "table_annovar.pl --remove --buildver hg19 \\\n",
      "    --outfile Exosome.genotypeGVCF.SNPs.hardfilter.vcf.avoutput --nastring . \\\n",
      "    --protocol refGene,cytoBand,genomicSuperDups,esp6500si_all,1000g2012apr_all,snp138,ljb23_all \\\n",
      "    --operation g,r,r,f,f,f,f \\\n",
      "    Exosome.genotypeGVCF.SNPs.hardfilter.vcf.ai.NA19240.avinput humandb/\n",
      "table_annovar.pl --remove --buildver hg19 \\\n",
      "    --outfile Exosome.genotypeGVCF.INDEL.hardfilter.vcf.avoutput --nastring . \\\n",
      "    --protocol refGene,cytoBand,genomicSuperDups,esp6500si_all,1000g2012apr_all,snp138,ljb23_all \\\n",
      "    --operation g,r,r,f,f,f,f \\\n",
      "    Exosome.genotypeGVCF.INDEL.hardfilter.vcf.ai.NA19240.avinput humandb/\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* --format vcf4\uff1a\u5236\u5b9a\u8f93\u5165\u683c\u5f0f\n",
      "* --allsample: \u8f6c\u6362vcf\u6587\u4ef6\u4e2d\u6240\u6709\u6837\u54c1\uff0c\u9ed8\u8ba4\u53ea\u8f6c\u6362\u7b2c\u4e00\u4e2a\u6837\u54c1\n",
      "* --includeinfo: \u5305\u542bvcf\u6587\u4ef6\u81ea\u5e26\u7684\u6ce8\u91ca\u4fe1\u606f\n",
      "* --comment: \u4fdd\u7559vcf\u7684\u6ce8\u91ca\u884c\n",
      "* --withzyg: \u540c\u65f6\u8f93\u51fazygosity/coverage/quality\n",
      "* --nastring: string to display when a score is not available\n",
      "* --protocol: comma-delimited string specifying database protocol \n",
      "    * `esp6500si_all` means allele frequency in the ESP6500 database. \n",
      "    * `snp138` means the SNP identifier in the dbSNP version 138. \n",
      "    * `LJB23*` contains prediction scores for non-synonymous variants using several widely used tools, including SIFT scores, PolyPhen2 HDIV scores, PolyPhen2 HVAR scores, LRT scores, MutationTaster scores, MutationAssessor score, FATHMM scores, GERP++ scores, PhyloP scores and SiPhy scores. \n",
      "* --operation: tells ANNOVAR which operations to use for each of the protocols: `g` means gene-based, `r` means region-based and `f` means filter-based."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For GATK: java -Xmx6g -jar GenomeAnalysisTK.jar -R example.fa -T UnifiedGenotper -I sampleSort.bam -o GATK.vcf -mbq 30 -glm BOTH\n",
      "\n",
      "For samtools: samtools mpileup -Q 13 -ugf example.fa sampleSort.bam | bcftools view -bvcg > sample.raw.bcf bcftools view sample.raw.bcf | vcfutils.pl varFilter -d 10 -w 5 -D 100 > samtools.vcf\n",
      "\n",
      "https://www.biostars.org/p/65413/"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}